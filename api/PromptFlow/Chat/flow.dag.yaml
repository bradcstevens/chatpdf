id: template_chat_flow
name: Template Chat Flow
environment:
  python_requirements_txt: requirements.txt
inputs:
  indexNs:
    type: string
    default: 3738d6dc992c4229a5a52efe84af4d3d
  indexType:
    type: string
    default: cogsearchvs
  postBody:
    type: object
    default:
      values:
      - recordId: 0
        data:
          history:
          - user: What is the scope of consolidation for Sumitomo Mitsui Financial Group?
            bot: The scope of consolidation for Sumitomo Mitsui Financial Group includes its
              consolidated subsidiaries. The consolidated financial statements
              for the year ended March 31, 2023, show that the Group had total
              assets of ¥270,428,564 million ($2,025,075 million) and total
              liabilities of ¥158,770,253 million ($1,188,934 million). The net
              assets of the Group were ¥111,658,311 million ($836,141 million).
              The consolidated balance sheet also provides details of the
              Group's assets, liabilities, and stockholders' equity. It is
              important to note that the financial statements are prepared in
              accordance with Japanese GAAP and may differ from IFRS.
          - user: How are the consolidated statement prepared at the company
          approach: rrr
          overrides:
            top: 3
            temperature: 0.3
            promptTemplate: "You are an AI assistant tasked with answering questions and
              summarizing information from\ 

              \        earning call transcripts, annual reports,
              SEC filings and financial statements.

              \        Your answer should accurately capture the
              key information in the document while avoiding the omission of any
              domain-specific words.\ 

              \        Please generate a concise and comprehensive
              information that includes details such as reporting year and
              amount in millions.

              \        Ensure that it is easy to understand for
              business professionals and provides an accurate representation of
              the financial statement history.\ 

              \       \ 

              \        Please remember to use clear language and
              maintain the integrity of the original information without missing
              any important details


              \        QUESTION: {question}

              \        =========

              \        {summaries}

              \        =========

              \        "
            suggest_followup_questions: true
            embeddingModelType: azureopenai
            firstSession: false
            session: '{"id":"h5q53g2n9ta8thdpsx86q","type":"Session","sessionId":"mygdad4vknfe2atw0mmfh6","name":"mygdad4vknfe2atw0mmfh6","chainType":"stuff","feature":"chat","indexId":"3738d6dc992c4229a5a52efe84af4d3d","indexType":"cogsearchvs","indexName":"smfc2022","llmModel":"gpt3.5","timestamp":"1693765265489","tokenUsed":0,"embeddingModelType":"azureopenai"}'
            sessionId: mygdad4vknfe2atw0mmfh6
            deploymentType: gpt3516k
            chainType: stuff
            searchType: hybrid
outputs:
  output:
    type: string
    reference: ${followup_questions.output}
    is_chat_output: true
  answer:
    type: string
    reference: ${followup_questions.output.values[0].data.answer}
  context:
    type: string
    reference: ${followup_questions.output.values[0].data.data_points}
nodes:
- name: augmented_chat
  type: llm
  source:
    type: code
    path: augmented_chat.jinja2
  inputs:
    deployment_name: chat16k
    max_tokens: 500
    systemmessage: ${extract_prompttemplate.output}
    contexts: ${search_question_from_vectordb.output}
    chat_history: ${parse_postBody.output.history}
    question: ${extract_query_from_history.output}
  provider: AzureOpenAI
  connection: aoai
  api: chat
  module: promptflow.tools.aoai
- name: create_llm
  type: python
  source:
    type: code
    path: create_llm.py
  inputs:
    overrides: ${parse_postBody.output.overrides}
    conn: entaoai
- name: parse_postBody
  type: python
  source:
    type: code
    path: parse_postBody.py
  inputs:
    postBody: ${inputs.postBody}
- name: insert_session
  type: python
  source:
    type: code
    path: insert_session.py
  inputs:
    overrides: ${parse_postBody.output.overrides}
    history: ${parse_postBody.output.history}
    conn: entaoai
- name: search_question_from_vectordb
  type: python
  source:
    type: code
    path: search_question_from_vectordb.py
  inputs:
    question: ${extract_query_from_history.output}
    embeddedQuestion: ${embed_the_question.output}
    indexType: ${inputs.indexType}
    indexNs: ${inputs.indexNs}
    conn: entaoai
    overrides: ${parse_postBody.output.overrides}
- name: extract_query_from_history
  type: llm
  source:
    type: code
    path: extract_query_from_history.jinja2
  inputs:
    deployment_name: chat16k
    max_tokens: 32
    chat_history: ${parse_postBody.output.history}
    question: ${extract_lastquestion.output}
  provider: AzureOpenAI
  connection: aoai
  api: chat
  module: promptflow.tools.aoai
- name: followup_questions
  type: python
  source:
    type: code
    path: followup_questions.py
  inputs:
    retrievedDocs: ${search_question_from_vectordb.output}
    question: ${extract_query_from_history.output}
    promptTemplate: ${extract_prompttemplate.output}
    llm: ${create_llm.output}
    modifiedAnswer: ${augmented_chat.output}
    indexType: ${inputs.indexType}
    indexNs: ${inputs.indexNs}
    conn: entaoai
    overrides: ${parse_postBody.output.overrides}
- name: extract_lastquestion
  type: python
  source:
    type: code
    path: extract_lastquestion.py
  inputs:
    history: ${parse_postBody.output.history}
- name: embed_the_question
  type: python
  source:
    type: code
    path: embed_the_question.py
  inputs:
    overrides: ${parse_postBody.output.overrides}
    conn: entaoai
    question: ${extract_query_from_history.output}
- name: extract_prompttemplate
  type: python
  source:
    type: code
    path: extract_prompttemplate.py
  inputs:
    overrides: ${parse_postBody.output.overrides}
